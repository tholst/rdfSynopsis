{"name":"Rdfsynopsis","tagline":"A framework and command-line tool for statistical analyses of RDF datasets.","body":"# rdfSynopsis\r\n\r\nThe software rdfSynopsis was written in Java. It uses the Apache Jena framework\r\n[6] to process RDF data and to query SPARQL endpoints. The goal for the design\r\nof RDFSynopsis was to write code that could be used both, as a stand-alone tool\r\noperated from the command-line, and as a framework of classes for reuse in other\r\nsoftware. \r\n\r\n***\r\n\r\n## Architecture\r\n\r\nThe figure below presents the class hierarchy and package arrangement.\r\nThree concepts are at the center of RDFSynopsis’s design: Datasets, Statistical\r\nCriteria, and Analyzers. The basic idea behind these concepts is to define a dataset\r\nanalysis in three steps.\r\n\r\n1. Define the dataset that shall be analyzed.\r\n1. Define the statistical criteria according to which the dataset shall be analyzed.\r\n1. Provide the dataset and the criteria to an analyzer, and let it do the work.\r\n\r\n![Architecture of rdfSynopsis](http://tholst.github.io/rdfSynopsis/classDiagram1.jpg)\r\n\r\n### Datasets\r\n\r\nA dataset represents any collection of RDF data. Our class SparqlDataset represents\r\ndatasets that can be queried with SPARQL queries. The class offers a\r\nsingle method query that can be used to pose SPARQL queries against the dataset.\r\nThroughout the code, we only use this method for data access. The subclasses\r\nSparqlEndpointDataset and InMemoryDataset encapsulate access to remote datasets\r\nwhich are identified via an endpoint URI, and local datasets which are loaded into\r\nmemory, respectively.\r\n\r\n```Java\r\npublic abstract class SparqlDataset extends Dataset {\t\r\n  public abstract QueryExecution query(Query query);\r\n}\r\n```\r\n\r\n### Statistical Criteria\r\n\r\nA statistical criterion represents a single analytic measure. The abstract class\r\nStatisticalCriterion provides three public methods. The first, flushLog, prints\r\nthe current state of measurements. The second, considerTriple, represents the\r\nfilterTriple(s, p, o) function, implementing the Triple\r\nStream Approach . The third public method is processSparqlDataset which implements\r\nthe Specific Query Approach. It uses the query method of the provided\r\nSparqlDataset, and delegates parsing of query results to its concrete subclasses. The\r\nspecific SPARQL queries for each criterion are loaded from separate .sparql-files.\r\nThis process is implemented in StatisticalCriterion, but has been omitted for\r\nbrevity.\r\n\r\n\r\n```Java\r\npublic abstract class StatisticalCriterion {  \r\n  // print current measurements\r\n  public abstract void flushLog(PrintStream ps);\r\n  \r\n  // filter triple (TSA)\r\n  public abstract \r\n  void considerTriple(Resource s, Property p, RDFNode o);\r\n\r\n  // process query results (SQA)\r\n  abstract void processQueryResults(ResultSet res);\r\n\r\n  // query dataset (SQA)\r\n  public void processSparqlDataset(SparqlDataset ds) {\r\n    ...\r\n    // execute query and obtain results\r\n    QueryExecution qe = ds.query(query);\r\n    ResultSet results = qe.execSelect();\r\n    \r\n    // delegate result processing to subclass\r\n    processQueryResults(results);  \r\n    ...\r\n  }\r\n}\r\n```\r\n\r\n### Analyzer\r\n\r\nAn analyzer represents a single analysis configuration. The AbstractAnalyzer\r\nclass defines four public methods. The first two, addCriterion and setDs, are\r\nused to configure the analysis with regard to dataset and criteria. The third method,\r\nperformAnalysis, actually performs the analysis and prints the results to the provided\r\nPrintStream. The fourth method is equals. AbstractAnalyzer and all subclasses\r\nof StatisticalCriterion re-implement this standard method, making analysis\r\nresults comparable by calling analyzer1.equals(analyzer2). The performAnalysis\r\nmethod is implemented differently for SQA and TSA. The subclass SparqlAnalyzer\r\n(SQA) calls processSparqlDataset for each criterion, while TripleStreamAnalyzer\r\n(TSA) creates a triple stream and calls considerTriple for each criterion and triple.\r\nThe triple stream is created by subsequently querying the dataset with increasing\r\nOFFSET parameters. Random Sampling is implemented by calling\r\nCollections.shuffle(offsets) on a precomputed list of offsets.\r\n\r\n\r\n```Java\r\npublic abstract class AbstractAnalyzer implements Analyzer {\r\n  // define criteria\r\n  public Analyzer addCriterion(StatisticalCriterion sc) { ... }\r\n  \r\n  // define dataset\r\n  public Analyzer setDs(SparqlDataset ds) { ... }\r\n  \r\n  // perform analysis and output results\r\n  public abstract void performAnalysis(PrintStream ps);\r\n  \r\n  // compare analysis results\r\n  @Override\r\n  public boolean equals(Object obj) { ... }\r\n}\r\n```\r\n\r\nThe classes in the eval package have been implemented for the evaluation of our\r\nwork, and do not represent core components of rdfSynopsis. Hence, they\r\nare not further discussed.\r\n\r\n***\r\n\r\n## Usage\r\n\r\n### Framework Usage\r\n\r\nThe following examples demonstrate the use of RDFSynopsis’s classes. We analyze\r\nthe number of triples of a SPARQL endpoint using TSA (Example 1), and find the\r\ncommon properties of an in-memory dataset using SQA (Example 2).\r\n\r\n#### Example 1\r\n```Java\r\nTripleStreamAnalyzer tsa = new TripleStreamAnalyzer()\r\n  .addCriterion(new NumTriples())\r\n  .setDs(new SparqlEndpointDataset(\"http://...\"))\r\n  .setRandomSampling(true)\r\n  .setTripleLimit(500);\r\ntsa.performAnalysis();\r\n```\r\n\r\n#### Example 2\r\n\r\n```Java\r\nSparqlAnalyzer sqa = new SparqlAnalyzer()\r\n  .addCriterion(new CommonProperties())\r\n  .setDs(new InMemoryDataset(\"file:../data/peel.rdf\"));\r\nsqa.performAnalysis();\r\n```\r\n\r\n### Command-Line Usage\r\n\r\nRDFSynopsis also provides a command-line interface. \r\n\r\n```\r\n> java -jar rdfSynopsis.jar --help\r\nUsage: rdfSynopsis [options]\r\n  Options:\r\n    -all, --allCriteria\r\n       Use all available criteria for analysis.\r\n       Default: false\r\n    -c, --criteria\r\n       A space-separated list of criteria to use for analysis, e.g, \"-c 3 5 7\"\r\n    -ep, --endpoint\r\n       The SPARQL endpoint URL that shall be analyzed.\r\n    -f, --file\r\n       The RDF dataset file that shall be analyzed.\r\n    -h, --help\r\n       Print this usage information.\r\n       Default: false\r\n    -lc, --listCriteria\r\n       Print list of analytical criteria.\r\n       Default: false\r\n    -mnq, --maximumNumberQueries\r\n       The maximum number of queries to perform a partial analysis; \"-1\" means \"infinite\". (TSA only, NA)\r\n       Default: -1\r\n    -ob, --orderBy\r\n       One of the following variables used to define an order in the triple stream: subject, predicate, object (TSA only)\r\n       Default: subject\r\n    -o, --outFile\r\n       The filename used to store analysis results. (NA)\r\n    -rand, --randomSampling\r\n       Use a \"random sampled\" triple stream. (TSA only)\r\n       Default: true\r\n    -rf, --resultFormat\r\n       One of the following result output formats: text,... (NA)\r\n       Default: text\r\n    -sqa, --specificQuery\r\n       Use one specific SPARQL query per criterion. (SQA)\r\n       Default: false\r\n    -tl, --tripleLimit\r\n       The maximum number of triples requested per query. (TSA only)\r\n       Default: 50000\r\n    -tsa, --tripleStream\r\n       Use generic SPARQL queries to create a triple stream. (TSA)\r\n       Default: false\r\n```\r\n\r\n```\r\n> java -jar rdfSynopsis.jar --listCriteria\r\n[id]\tcriterion\r\n------------------------------------------\r\n[1]\tclass usage count\r\n[2]\ttriples per subject class\r\n[3]\texplicit class hierarchy\r\n[4]\timplicit class hierarchy\r\n[5]\tontology-ratio\r\n[6]\ttyped-subject-ratio\r\n[7]\tproperty usage\r\n[8]\tpredicate vocabularies\r\n[9]\tproperty usage\tper subject class\r\n[10]\tclass instances per property\r\n[11]\texplicit property hierarchy\r\n[12]\timplicit property hierarchy\r\n[13]\tdistinct blank subjects\r\n[14]\tnamespace links\r\n[15]\tdistinct subject-only blanks\r\n[16]\ttriples\r\n[17]\tsameAs\r\n[18]\tcommon properties\r\n```\r\n\r\n\r\n\r\nThe above examples can be invoked from the command-line. The -c parameter is used followed by a list of\r\nnumbers to define the desired criteria; -lc prints the number-to-criteria mapping.\r\n\r\n#### Example 1\r\n```\r\n> java -jar rdfSynopsis.jar -tsa -rand -tl 500 -c 16 -ep http...\r\n```\r\n\r\n#### Example 2\r\n```\r\n> java -jar rdfSynopsis.jar -sqa -c 18 -f ../data/peel.rdf\r\n```\r\n\r\n***\r\n\r\n## Installation\r\n\r\n***\r\n\r\n## Known Bugs, Problems, Shortcomings\r\n\r\n***\r\n\r\n## License","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}